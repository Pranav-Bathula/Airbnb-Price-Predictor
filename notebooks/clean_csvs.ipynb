{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7391acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/notebooks\n",
      "Project root: /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor\n",
      "Data directory: /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/data\n",
      "\n",
      "Processing listings for cities: NYC, Boston, Washington_DC\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up paths - when running from notebooks/ directory\n",
    "current_dir = Path().resolve()\n",
    "# If we're in notebooks/, go up one level to project root\n",
    "project_root = current_dir.parent if current_dir.name == \"notebooks\" else current_dir\n",
    "data_dir = project_root / \"data\"\n",
    "\n",
    "# City folders to process\n",
    "cities = [\"NYC\", \"Boston\", \"Washington_DC\"]\n",
    "\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"\\nProcessing listings for cities: {', '.join(cities)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477b9001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing NYC...\n",
      "============================================================\n",
      "Original shape: (36111, 79)\n",
      "After price cleaning shape: (21328, 79)\n",
      "Removed 14783 rows with invalid prices\n",
      "[NYC] rows before outlier filters: 21328\n",
      "[NYC] rows after outlier filters:  14382\n",
      "\n",
      "============================================================\n",
      "Processing Boston...\n",
      "============================================================\n",
      "Original shape: (4419, 79)\n",
      "After price cleaning shape: (3506, 79)\n",
      "Removed 913 rows with invalid prices\n",
      "[Boston] rows before outlier filters: 3506\n",
      "[Boston] rows after outlier filters:  2669\n",
      "\n",
      "============================================================\n",
      "Processing Washington_DC...\n",
      "============================================================\n",
      "Original shape: (6423, 79)\n",
      "After price cleaning shape: (4846, 79)\n",
      "Removed 1577 rows with invalid prices\n",
      "[Washington_DC] rows before outlier filters: 4846\n",
      "[Washington_DC] rows after outlier filters:  4075\n",
      "\n",
      "============================================================\n",
      "Summary: Processed 3 cities\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Process each city's listings\n",
    "all_cleaned_data = []\n",
    "\n",
    "for city in cities:\n",
    "    city_dir = data_dir / city\n",
    "    listings_path = city_dir / \"listings.csv\"\n",
    "    \n",
    "    if not listings_path.exists():\n",
    "        print(f\"⚠ Skipping {city}: {listings_path} not found\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {city}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Read the listings CSV\n",
    "    df = pd.read_csv(listings_path)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    \n",
    "    # -------------------------\n",
    "    # Basic price cleaning\n",
    "    # -------------------------\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Remove $ and commas from price, convert to numeric\n",
    "    price_str = (\n",
    "        df_clean[\"price\"]\n",
    "          .astype(str)\n",
    "          .str.replace(\"$\", \"\", regex=False)\n",
    "          .str.replace(\",\", \"\", regex=False)\n",
    "          .str.strip()\n",
    "    )\n",
    "    \n",
    "    df_clean[\"price\"] = pd.to_numeric(price_str, errors=\"coerce\")\n",
    "    \n",
    "    # Remove rows with missing or invalid prices\n",
    "    original_count = len(df_clean)\n",
    "    df_clean = df_clean[df_clean[\"price\"].notna()]\n",
    "    df_clean = df_clean[df_clean[\"price\"] > 0]\n",
    "    \n",
    "    print(f\"After price cleaning shape: {df_clean.shape}\")\n",
    "    print(f\"Removed {original_count - len(df_clean)} rows with invalid prices\")\n",
    "    \n",
    "    # -------------------------\n",
    "    # Extra row-level cleaning\n",
    "    # (same logic as model notebook)\n",
    "    # -------------------------\n",
    "    rows_before = len(df_clean)\n",
    "    \n",
    "    # If host_since + last_review exist, compute host_years here\n",
    "    if \"host_since\" in df_clean.columns and \"last_review\" in df_clean.columns:\n",
    "        df_clean[\"host_since_dt\"] = pd.to_datetime(df_clean[\"host_since\"], errors=\"coerce\")\n",
    "        df_clean[\"last_review_dt\"] = pd.to_datetime(df_clean[\"last_review\"], errors=\"coerce\")\n",
    "        ref_date = df_clean[\"last_review_dt\"].max()\n",
    "        df_clean[\"host_years\"] = (ref_date - df_clean[\"host_since_dt\"]).dt.days / 365.25\n",
    "    \n",
    "    # helper: return all True if column doesn't exist\n",
    "    def between_if_col(df_local, col, low, high):\n",
    "        if col in df_local.columns:\n",
    "            return df_local[col].between(low, high)\n",
    "        else:\n",
    "            return pd.Series(True, index=df_local.index)\n",
    "    \n",
    "    # base mask\n",
    "    mask = (\n",
    "        df_clean[\"price\"].between(10, 1000)\n",
    "        & between_if_col(df_clean, \"accommodates\", 1, 10)\n",
    "        & between_if_col(df_clean, \"bedrooms\", 0, 8)\n",
    "        & between_if_col(df_clean, \"beds\", 0, 10)\n",
    "        & between_if_col(df_clean, \"bathrooms\", 0, 5)\n",
    "        & between_if_col(df_clean, \"review_scores_rating\", 1, 5)\n",
    "        & between_if_col(df_clean, \"availability_365\", 0, 365)\n",
    "        & between_if_col(df_clean, \"reviews_per_month\", 0, 20)\n",
    "    )\n",
    "    \n",
    "    # add host_years constraint if we computed it\n",
    "    if \"host_years\" in df_clean.columns:\n",
    "        mask &= df_clean[\"host_years\"].between(0, 20)\n",
    "    \n",
    "    df_clean = df_clean[mask]\n",
    "    \n",
    "    print(f\"[{city}] rows before outlier filters: {rows_before}\")\n",
    "    print(f\"[{city}] rows after outlier filters:  {len(df_clean)}\")\n",
    "    \n",
    "    # Store cleaned data with city identifier\n",
    "    all_cleaned_data.append((city, df_clean))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Summary: Processed {len(all_cleaned_data)} cities\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3597e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NYC: Saved 14382 listings to /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/data/processed/NYC_listings_cleaned.csv\n",
      "✓ Boston: Saved 2669 listings to /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/data/processed/Boston_listings_cleaned.csv\n",
      "✓ Washington_DC: Saved 4075 listings to /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/data/processed/Washington_DC_listings_cleaned.csv\n",
      "\n",
      "✓ All cleaned data saved!\n",
      "\n",
      "Saved files:\n",
      "  - /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/data/processed/NYC_listings_cleaned.csv\n",
      "  - /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/data/processed/Boston_listings_cleaned.csv\n",
      "  - /Users/pranavbathula/Library/CloudStorage/Box-Box/DATA MANAGEMENT FOR DATA SCIENCE/Airbnb-Price-Predictor/data/processed/Washington_DC_listings_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned CSVs for each city\n",
    "processed_dir = data_dir / \"processed\"\n",
    "processed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "saved_files = []\n",
    "\n",
    "for city, df_clean in all_cleaned_data:\n",
    "    # Save to processed folder with city name\n",
    "    out_path = processed_dir / f\"{city}_listings_cleaned.csv\"\n",
    "    df_clean.to_csv(out_path, index=False)\n",
    "    saved_files.append(str(out_path))\n",
    "    print(f\"✓ {city}: Saved {len(df_clean)} listings to {out_path}\")\n",
    "\n",
    "print(f\"\\n✓ All cleaned data saved!\")\n",
    "print(f\"\\nSaved files:\")\n",
    "for f in saved_files:\n",
    "    print(f\"  - {f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
